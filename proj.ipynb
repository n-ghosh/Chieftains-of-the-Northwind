{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u99VSREuMEL"
      },
      "source": [
        "## Chieftains of the Northwind"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAb1ujVw_jR5",
        "outputId": "186faa48-dfb0-41cf-bedb-537dba4ff943"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (2.2.1)\n",
            "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\oshom\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.12_qbz5n2kfra8p0\\localcache\\local-packages\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG2_B6ZRuMEO"
      },
      "source": [
        "### Section 1: Clean Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tK9pCFE4uMEP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "0CYv9q5kuMEP",
        "outputId": "794f70bf-984c-423a-d4ff-a8d2ba703b93"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>triage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am 35 years old unmarried , i was diagonized...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have been having abdominal pain and burning ...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sir, Day before yesterday i had an oil fried i...</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>friend has a lump where their coccyx is, has b...</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which demographic should raise suspicion of a ...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42508</th>\n",
              "      <td>My wife is having sharp pains in left chest ab...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42509</th>\n",
              "      <td>BACKGROUND: Survivors of critical coronavirus ...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42510</th>\n",
              "      <td>Hi, My mum had an operation the doctors though...</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42511</th>\n",
              "      <td>My 6 yr old daughter has had a ever for 3 dats...</td>\n",
              "      <td>urgent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42512</th>\n",
              "      <td>Hi, may I answer your health queries right now...</td>\n",
              "      <td>non-urgent</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42513 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question      triage\n",
              "0      I am 35 years old unmarried , i was diagonized...  non-urgent\n",
              "1      I have been having abdominal pain and burning ...  non-urgent\n",
              "2      sir, Day before yesterday i had an oil fried i...      urgent\n",
              "3      friend has a lump where their coccyx is, has b...      urgent\n",
              "4      Which demographic should raise suspicion of a ...  non-urgent\n",
              "...                                                  ...         ...\n",
              "42508  My wife is having sharp pains in left chest ab...  non-urgent\n",
              "42509  BACKGROUND: Survivors of critical coronavirus ...  non-urgent\n",
              "42510  Hi, My mum had an operation the doctors though...      urgent\n",
              "42511  My 6 yr old daughter has had a ever for 3 dats...      urgent\n",
              "42512  Hi, may I answer your health queries right now...  non-urgent\n",
              "\n",
              "[42513 rows x 2 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('dataset_triage.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmLUMLj3uMEP",
        "outputId": "fc0a52cc-5443-4ca4-cc94-dd34f0e0a0b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42513 entries, 0 to 42512\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   question  42513 non-null  object\n",
            " 1   triage    42513 non-null  object\n",
            "dtypes: object(2)\n",
            "memory usage: 664.4+ KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YfRS8oecuMEP",
        "outputId": "fb126a9f-6090-424b-c70f-596b106c264e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>triage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [question, triage]\n",
              "Index: []"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#NAN row checking\n",
        "df[df.isnull().T.any().T]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEvgg-zguMEP",
        "outputId": "28912788-2568-44f9-9f6f-2a1a640eaac7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "triage\n",
              "non-urgent    30799\n",
              "urgent        11714\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['question'] = df['question'].astype('string')\n",
        "df['triage'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QLJja74duMEQ",
        "outputId": "30c9de36-6e4f-43b6-bc3d-92be917cd3cc"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>triage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I am 35 years old unmarried , i was diagonized...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I have been having abdominal pain and burning ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sir, Day before yesterday i had an oil fried i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>friend has a lump where their coccyx is, has b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Which demographic should raise suspicion of a ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42508</th>\n",
              "      <td>My wife is having sharp pains in left chest ab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42509</th>\n",
              "      <td>BACKGROUND: Survivors of critical coronavirus ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42510</th>\n",
              "      <td>Hi, My mum had an operation the doctors though...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42511</th>\n",
              "      <td>My 6 yr old daughter has had a ever for 3 dats...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42512</th>\n",
              "      <td>Hi, may I answer your health queries right now...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>42513 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  triage\n",
              "0      I am 35 years old unmarried , i was diagonized...       0\n",
              "1      I have been having abdominal pain and burning ...       0\n",
              "2      sir, Day before yesterday i had an oil fried i...       1\n",
              "3      friend has a lump where their coccyx is, has b...       1\n",
              "4      Which demographic should raise suspicion of a ...       0\n",
              "...                                                  ...     ...\n",
              "42508  My wife is having sharp pains in left chest ab...       0\n",
              "42509  BACKGROUND: Survivors of critical coronavirus ...       0\n",
              "42510  Hi, My mum had an operation the doctors though...       1\n",
              "42511  My 6 yr old daughter has had a ever for 3 dats...       1\n",
              "42512  Hi, may I answer your health queries right now...       0\n",
              "\n",
              "[42513 rows x 2 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id2label = {0: 'non-urgent', 1: 'urgent'}\n",
        "df['triage'] = df['triage'].apply(lambda x: 0 if x == 'non-urgent' else 1)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1fBCW95uMEQ",
        "outputId": "606c9aa5-ed66-40c8-8c20-53e3ccae1c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 42513 entries, 0 to 42512\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   question  42513 non-null  string\n",
            " 1   triage    42513 non-null  int64 \n",
            "dtypes: int64(1), string(1)\n",
            "memory usage: 664.4 KB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHKN0L7SuMEQ"
      },
      "source": [
        "### Section 2: Prepare Data for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ew2vKlpMukHi",
        "outputId": "d0f9c9fa-8ad6-4c1d-dc32-6fe83c2a4e70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
            "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.29.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N6Ir_tWzuMEQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import evaluate\n",
        "from transformers import DistilBertForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "import torch as pt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVHdoXHYuMER",
        "outputId": "4088c74f-338e-43f7-ec2a-e21a29ba96f1"
      },
      "outputs": [],
      "source": [
        "model_name = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Adding the below cell after initial training, trying different models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
        "# model_name = \"google/electra-small-discriminator\"\n",
        "# tokenizer = ElectraTokenizer.from_pretrained(model_name)\n",
        "# model = ElectraForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n",
        "model_name = \"roberta-base\"\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(model_name)\n",
        "model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "YDe9c4VvuMER"
      },
      "outputs": [],
      "source": [
        "train_texts, val_texts, train_labels, val_labels = train_test_split(df[\"question\"], df[\"triage\"], test_size=0.2, shuffle=True)\n",
        "\n",
        "train_texts = train_texts.reset_index(drop=True)\n",
        "val_texts = val_texts.reset_index(drop=True)\n",
        "train_labels = train_labels.reset_index(drop=True).array\n",
        "val_labels = val_labels.reset_index(drop=True).array\n",
        "\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True)\n",
        "val_encodings = tokenizer(list(val_texts), truncation=True, padding=True)\n",
        "\n",
        "class QuestionsDataset(pt.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: pt.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        if self.labels:\n",
        "            item[\"labels\"] = pt.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_data = QuestionsDataset(train_encodings, train_labels)\n",
        "val_data = QuestionsDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "\n",
        "def init_trainer(model, epochs = 2, out_dir = \"./results\"):\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir = out_dir,\n",
        "        num_train_epochs = epochs,\n",
        "        evaluation_strategy='steps',\n",
        "        logging_dir='./logs',\n",
        "        logging_steps = 10,\n",
        "        logging_first_step = True,\n",
        "        warmup_steps = 500,\n",
        "        weight_decay=0.01,\n",
        "        per_device_train_batch_size = 16,\n",
        "        per_device_eval_batch_size = 64,\n",
        "        gradient_accumulation_steps = 8, \n",
        "        gradient_checkpointing=True,\n",
        "        # fp16 = True,\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_data,\n",
        "        eval_dataset=val_data,\n",
        "        compute_metrics=compute_metrics,\n",
        "    )\n",
        "\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Fine-tune the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwsieHY2uMER",
        "outputId": "bfadc80b-8c6a-4192-af48-1920bb31406f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7b2b764fb640>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer1 = init_trainer(model, 2, \"./results/train1\") # this model is DistilBert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "milG0STKuMES",
        "outputId": "5116410e-8308-4655-a42e-df90be01a224"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4252' max='4252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4252/4252 54:31, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.342400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.554600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.541900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.557200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.523300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.528800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.519600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.526100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.489600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.508300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.502200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.508200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.497800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.507900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.508100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.473300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.487100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.461200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.487700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.497400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.426400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.425500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.447200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.428500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.409100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.423900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.400900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.423300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.416200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.413300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.395400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.394100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.424800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.398300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.378100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.414500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.380300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.418600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.383100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.377800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4200</td>\n",
              "      <td>0.407100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4252, training_loss=0.4703510521104172, metrics={'train_runtime': 3275.0055, 'train_samples_per_second': 20.769, 'train_steps_per_second': 1.298, 'total_flos': 9010432456581120.0, 'train_loss': 0.4703510521104172, 'epoch': 2.0})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer1.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ktYpqvCSuMES"
      },
      "outputs": [],
      "source": [
        "trainer1.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "yA679I6EuMES",
        "outputId": "a4e63ba5-531c-4fa2-f854-a5c5d2428b68"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='133' max='133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [133/133 02:27]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5091649889945984,\n",
              " 'eval_accuracy': 0.7637304480771493,\n",
              " 'eval_runtime': 148.4871,\n",
              " 'eval_samples_per_second': 57.264,\n",
              " 'eval_steps_per_second': 0.896,\n",
              " 'epoch': 2.0}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer1.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer2 = init_trainer(model, 2, \"./results/train2\") # this model is Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/264 [01:58<?, ?it/s]\n",
            "                                                 \n",
            "  0%|          | 1/530 [00:58<8:38:49, 58.85s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7174, 'learning_rate': 1.0000000000000001e-07, 'epoch': 0.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                  \n",
            "  2%|▏         | 10/530 [09:58<8:38:16, 59.80s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 0.7247, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.04}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\u001b[A\n",
            "\n",
            "                                                  \n",
            "\u001b[A                                    \n",
            "  2%|▏         | 10/530 [23:59<8:38:16, 59.80s/it]\n",
            "\u001b[A/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.7149145603179932, 'eval_accuracy': 0.2788427613783371, 'eval_runtime': 841.6844, 'eval_samples_per_second': 10.102, 'eval_steps_per_second': 0.158, 'epoch': 0.04}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  2%|▏         | 11/530 [25:02<45:54:19, 318.42s/it]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[55], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer2 \u001b[38;5;241m=\u001b[39m init_trainer(model, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/train2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/transformers/trainer.py:2781\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2779\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2781\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/accelerate/accelerator.py:2001\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1985\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, loss, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1986\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1987\u001b[0m \u001b[38;5;124;03m    Scales the gradients in accordance to the `GradientAccumulationPlugin` and calls the correct `backward()` based\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m \u001b[38;5;124;03m    on the configuration.\u001b[39;00m\n\u001b[1;32m   1989\u001b[0m \n\u001b[1;32m   1990\u001b[0m \u001b[38;5;124;03m    Should be used in lieu of `loss.backward()`.\u001b[39;00m\n\u001b[1;32m   1991\u001b[0m \n\u001b[1;32m   1992\u001b[0m \u001b[38;5;124;03m    Example:\u001b[39;00m\n\u001b[1;32m   1993\u001b[0m \n\u001b[1;32m   1994\u001b[0m \u001b[38;5;124;03m    ```python\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[38;5;124;03m    >>> from accelerate import Accelerator\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m \n\u001b[1;32m   1997\u001b[0m \u001b[38;5;124;03m    >>> accelerator = Accelerator(gradient_accumulation_steps=2)\u001b[39;00m\n\u001b[1;32m   1998\u001b[0m \u001b[38;5;124;03m    >>> outputs = model(inputs)\u001b[39;00m\n\u001b[1;32m   1999\u001b[0m \u001b[38;5;124;03m    >>> loss = loss_fn(outputs, labels)\u001b[39;00m\n\u001b[1;32m   2000\u001b[0m \u001b[38;5;124;03m    >>> accelerator.backward(loss)\u001b[39;00m\n\u001b[0;32m-> 2001\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistributed_type \u001b[38;5;241m!=\u001b[39m DistributedType\u001b[38;5;241m.\u001b[39mDEEPSPEED:\n\u001b[1;32m   2004\u001b[0m         \u001b[38;5;66;03m# deepspeed handles loss scaling by gradient_accumulation_steps in its `backward`\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m         loss \u001b[38;5;241m=\u001b[39m loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "trainer2.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer2.save_model()\n",
        "trainer2.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Test the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.29.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (2.2.0)\n",
            "Requirement already satisfied: huggingface-hub in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.12.2)\n",
            "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.29.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.1.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "%pip install accelerate -U\n",
        "from transformers import DistilBertForSequenceClassification, AutoTokenizer\n",
        "import torch as pt\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "id2label = {0: 'non-urgent', 1: 'urgent'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(\"./results/train1\", local_files_only=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'urgent'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def test_model(message):\n",
        "  encodings = tokenizer(message, truncation=True, padding=True, return_tensors=\"pt\")\n",
        "  output = model(**encodings)\n",
        "  result = pt.argmax(output.logits).item()\n",
        "  return id2label[result]\n",
        "\n",
        "test_model(\"Please help, what should I do? My father fell and he can't get up.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'non-urgent'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(\"What does it mean if my son gets sick every time we go to swimming lessons?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'urgent'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(\"Please help!! My baby is crying urgently!\") # bad parent, not urgent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'urgent'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_model(\"What do I do? My mommy isn't waking up I'm poking her and she won't move.\") # mom could be dead, urgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "AI generated examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n"
          ]
        }
      ],
      "source": [
        "examples_urgent = (\n",
        "    \"I'm experiencing severe chest pain and shortness of breath. I think I may be having a heart attack.\",\n",
        "    \"My child has a high fever of 104°F and has been vomiting for the past 6 hours. We need to be seen immediately.\",\n",
        "    \"I just had a bad fall and I think my arm might be broken. I'm in a lot of pain and need to come in right away.\",\n",
        "    \"I'm pregnant and I'm bleeding heavily. I'm very concerned and need to speak with a doctor as soon as possible.\",\n",
        "    \"I've been experiencing severe abdominal pain and diarrhea for the past 24 hours. I'm feeling extremely weak and dehydrated.\")\n",
        "\n",
        "for example in examples_urgent:\n",
        "    print(test_model(example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n"
          ]
        }
      ],
      "source": [
        "examples_nonurgent = (\n",
        "    \"Hello, I was wondering if I could schedule an appointment for a routine check-up next week?\",\n",
        "    \"I need to refill my prescription for blood pressure medication. Could you please send a refill request to my pharmacy?\",\n",
        "    \"I have a question about the side effects of the medication I'm currently taking. Is there a good time I could speak with a nurse?\",\n",
        "    \"I'd like to get a flu shot this year. Can you let me know when the clinic has the flu vaccine available?\",\n",
        "    \"I need to update my insurance information on file. Could you please provide me with the necessary forms?\",)\n",
        "\n",
        "for example in examples_nonurgent:\n",
        "    print(test_model(example))\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "urgent\n",
            "non-urgent\n"
          ]
        }
      ],
      "source": [
        "examples_trick = (\n",
        "    \"Please help!! My baby is crying urgently!\",\n",
        "    \"I have a terrible headache, it's an emergency!\",\n",
        "    \"I need to schedule a very urgent appointment for a papercut.\",\n",
        "    \"It's an absolute crisis, I broke a nail!\",\n",
        "    \"This is an emergency! I ran out of my daily multivitamin.\",\n",
        "    \"I'm having an urgent problem with a hangnail, I need to be seen right away!\",\n",
        "    \"Emergency! I stubbed my toe and it's a little bruised.\",\n",
        "    \"Urgent request: I need a refill on my dandruff shampoo.\",\n",
        "    \"This is an urgent matter - I need the phone number for a dog groomer.\",\n",
        "    \"I'm having an emergency allergic reaction to pollen. Just kidding, I'm fine!\"\n",
        ")\n",
        "\n",
        "for example in examples_trick:\n",
        "    print(test_model(example))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n",
            "non-urgent\n"
          ]
        }
      ],
      "source": [
        "examples_false_neg = (\n",
        "    \"There's some blood in my urine, but I did just start a new medication so that might be causing it.\",\n",
        "    \"I'm feeling a little dizzy and lightheaded, but I'm sure it's nothing serious.\",\n",
        "    \"I have a sharp pain in my lower abdomen, but it comes and goes so I'm not too worried.\",\n",
        "    \"I found a lump in my breast, but I'm sure it's just a harmless cyst.\",\n",
        "    \"I was playing basketball and took a hard fall on my knee. It's swollen but I can still walk on it.\",\n",
        "        \"My son fell off the monkey bars at the park and hit his head pretty hard. He says he feels fine though.\",\n",
        "    \"I've had this really bad headache for 3 days straight now. Could be a migraine or something?\",\n",
        "    \"I'm a type 1 diabetic and my blood sugar has been over 300 for most of the day. Should I be concerned?\",\n",
        "    \"My Dad is 75 and has been having trouble remembering things lately. Is that just normal aging?\", \n",
        "    \"I'm 32 weeks pregnant and haven't felt the baby move much today. Could you let me know if that's ok?\",\n",
        "    \"I've had some tightness in my chest and arm numbness for a few hours now. Maybe I slept weird?\",\n",
        "    \"My 3-year-old daughter spiked a fever of 103 this morning but she's acting totally normal otherwise.\",\n",
        "    \"There's blood in my stool, maybe it's just hemorrhoids? I've had them before so hopefully that's all it is.\"\n",
        ")\n",
        "\n",
        "for example in examples_false_neg:\n",
        "    print(test_model(example))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
